{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbrBqe7B7JC9",
        "outputId": "b78318cd-66f1-4b4c-b02d-689129f85f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7tKMETOfLW2"
      },
      "source": [
        "##Load and Preprocess PDF Files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "def load_pdfs_from_zip(zip_path):\n",
        "    \"\"\"Loads PDF files from a ZIP file and extracts their text.\"\"\"\n",
        "    extracted_texts = {}\n",
        "    temp_dir = \"temp_documents\"\n",
        "\n",
        "    # Unzip the documents\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "    # Iterate through the extracted PDF files\n",
        "    for pdf_file in Path(temp_dir).rglob(\"*.pdf\"):\n",
        "        extracted_texts[pdf_file.name] = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    # Clean up the temporary directory\n",
        "    for file in Path(temp_dir).glob(\"*\"):\n",
        "        if file.is_file():\n",
        "            file.unlink()\n",
        "        else:\n",
        "            for subfile in file.glob(\"*\"):\n",
        "                subfile.unlink()\n",
        "            file.rmdir()\n",
        "    Path(temp_dir).rmdir()\n",
        "\n",
        "    return extracted_texts\n"
      ],
      "metadata": {
        "id": "KTm0-6WTvYam"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boolean Retrieval Model"
      ],
      "metadata": {
        "id": "EVJ11zFy9X8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boolean_search(documents, query):\n",
        "    \"\"\"\n",
        "    Performs a boolean search over documents.\n",
        "    Supports queries with AND, OR, NOT operators.\n",
        "    \"\"\"\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    query = query.lower()\n",
        "    query_tokens = tokenizer.tokenize(query)\n",
        "\n",
        "    results = {}\n",
        "    for doc_name, content in documents.items():\n",
        "        content_tokens = set(tokenizer.tokenize(content.lower()))\n",
        "\n",
        "        # Split the content into lines\n",
        "        lines = content.split(\"\\n\")\n",
        "\n",
        "        matching_lines = []  # To store matching lines for this document\n",
        "\n",
        "        # Handle simple AND, OR, NOT queries\n",
        "        if \"and\" in query_tokens:\n",
        "            terms = [t for t in query_tokens if t != \"and\"]\n",
        "            if all(term in content_tokens for term in terms):\n",
        "                # Add lines that contain the query terms\n",
        "                matching_lines = [line for line in lines if all(term in line.lower() for term in terms)]\n",
        "        elif \"or\" in query_tokens:\n",
        "            terms = [t for t in query_tokens if t != \"or\"]\n",
        "            if any(term in content_tokens for term in terms):\n",
        "                # Add lines that contain any of the query terms\n",
        "                matching_lines = [line for line in lines if any(term in line.lower() for term in terms)]\n",
        "        elif \"not\" in query_tokens:\n",
        "            term = query_tokens[query_tokens.index(\"not\") + 1]\n",
        "            if term not in content_tokens:\n",
        "                # Add lines that do not contain the term\n",
        "                matching_lines = [line for line in lines if term not in line.lower()]\n",
        "        else:  # Single term\n",
        "            if query in content_tokens:\n",
        "                # Add lines that contain the query term\n",
        "                matching_lines = [line for line in lines if query in line.lower()]\n",
        "\n",
        "        if matching_lines:\n",
        "            results[doc_name] = matching_lines\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "7cHLMbeOudUV"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Space Model"
      ],
      "metadata": {
        "id": "e2kh71LC9dnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_space_search(documents, query, top_n=10):\n",
        "    \"\"\"\n",
        "    Performs a vector space search using TF-IDF.\n",
        "    Returns the top N most relevant documents and matching lines.\n",
        "    \"\"\"\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    query_tokens = \" \".join(tokenizer.tokenize(query.lower()))\n",
        "\n",
        "    # Prepare TF-IDF matrix\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    doc_names = list(documents.keys())\n",
        "    doc_texts = list(documents.values())\n",
        "    tfidf_matrix = vectorizer.fit_transform(doc_texts)\n",
        "\n",
        "    # Transform query into the same TF-IDF space\n",
        "    query_vector = vectorizer.transform([query_tokens])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
        "\n",
        "    # Get the top N results\n",
        "    top_documents = [(doc_names[i], similarities[i], doc_texts[i]) for i in top_indices]\n",
        "\n",
        "    # Find matching lines for each of the top N documents\n",
        "    results = {}\n",
        "    for doc_name, score, content in top_documents:\n",
        "        lines = content.split(\"\\n\")\n",
        "        matching_lines = [line for line in lines if query.lower() in line.lower()]\n",
        "        if matching_lines:\n",
        "            results[doc_name] = matching_lines\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "Fu0x021IvR_m"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main Script"
      ],
      "metadata": {
        "id": "uA1O0EYv9hlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    zip_path = \"/content/drive/MyDrive/phase2/Documents.zip\"  # Path to your ZIP file containing PDFs\n",
        "\n",
        "    print(\"Loading documents...\")\n",
        "    documents = load_pdfs_from_zip(zip_path)\n",
        "    print(f\"Documents loaded: {documents.keys()}\")\n",
        "\n",
        "    # # Print all document names\n",
        "    # print(\"All Document Names:\")\n",
        "    # for doc_name in documents.keys():\n",
        "    #   print(doc_name)\n",
        "\n",
        "    # Example usage of Boolean Retrieval Model\n",
        "    print(\"\\n--- Boolean Search ---\")\n",
        "    boolean_query = \"factors AND must AND be AND considered\"\n",
        "    # factors AND must AND be AND considered\n",
        "    boolean_results = boolean_search(documents, boolean_query)\n",
        "    print(f\"Boolean Search Results for '{boolean_query}':\")\n",
        "    for doc, lines in boolean_results.items():\n",
        "        print(f\"Document: {doc}\")\n",
        "        for line in lines:\n",
        "            print(f\"  Line: {line}\")\n",
        "\n",
        "    # Example usage of Vector Space Model\n",
        "    print(\"\\n--- Vector Space Search ---\")\n",
        "    vector_query = \"may be commonly held\"\n",
        "    vector_results = vector_space_search(documents, vector_query, top_n=10)\n",
        "    print(f\"Vector Space Search Results for '{vector_query}':\")\n",
        "    for doc, lines in vector_results.items():\n",
        "        print(f\"Document: {doc}\")\n",
        "        for line in lines:\n",
        "            print(f\"  Line: {line}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yaux96eDvcTj"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjYT2ZOqxAT8",
        "outputId": "89ded68f-64f3-4ee7-c485-eec510fc795d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents...\n",
            "Documents loaded: dict_keys(['Disruptive, Impulse-Control, and Conduct Disorders.pdf', 'Personality Disorders.pdf', 'Other Mental Disorders.pdf', 'Depressive Disorders.pdf', 'Gender Dysphoria.pdf', 'Anxiety Disorders.pdf', 'Feeding and Eating Disorders.pdf', 'Paraphilic Disorders.pdf', 'Trauma- and Stressor-Related Disorders.pdf', 'Obsessive-Compulsive and Related Disorders.pdf', 'Elimination Disorders.pdf', 'Neurodevelopmental Disorders.pdf', 'Sexual Dysfunctions.pdf', 'Dissociative Disorders.pdf', 'Schizophrenia Spectrum and Other Psychotic Disorders.pdf', 'Neurocognitive Disorders.pdf', 'Sleep-Wake Disorders.pdf', 'Medication-Induced Movement Disorders and.pdf', 'Bipolar and Related Disorders.pdf', 'Substance-Related and Addictive Disorders.pdf', 'Other Conditions That May Be a Focus of Clinical Attention.pdf', 'Somatic Symptom and Related Disorders.pdf'])\n",
            "\n",
            "--- Boolean Search ---\n",
            "Boolean Search Results for 'factors AND must AND be AND considered':\n",
            "Document: Sexual Dysfunctions.pdf\n",
            "  Line: of factors must be considered during the asse ssment of sexual dysfunction, given that they\n",
            "  Line: lowing five factors must be considered during assessment and diagnosis of delayed ejacu-\n",
            "  Line: lowing five factors must be considered during  assessment and diagnosis of erectile disorder\n",
            "  Line: lowing five factors must be considered during assessment and diagnosis of female orgas-\n",
            "  Line: ing five factors must be considered during asse ssment and diagnosis of female sexual interest/\n",
            "  Line: lowing five factors must be considered duri ng assessment and diagnosis of male hypo-\n",
            "Document: Schizophrenia Spectrum and Other Psychotic Disorders.pdf\n",
            "  Line: Cultural and socioeconomic factors must be considered, particularly  when the individual\n",
            "  Line: Cultural and socioeconomic factors must be considered, particularly  when the individual\n",
            "\n",
            "--- Vector Space Search ---\n",
            "Vector Space Search Results for 'may be commonly held':\n",
            "Document: Schizophrenia Spectrum and Other Psychotic Disorders.pdf\n",
            "  Line: appear to be delusional in one culture (e.g.,  witchcraft) may be commonly held in another.\n",
            "  Line: pear to be delusional in one culture (e.g., witchcraft) may be commonly held in another.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9Y8l_ea98Zj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}